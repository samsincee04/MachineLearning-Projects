{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg3plnU5OYxc",
        "outputId": "07ff46db-7ba8-496e-b0b2-7ca16ce542e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from torchvision.datasets import CIFAR10\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRnqSDrWkil5"
      },
      "outputs": [],
      "source": [
        "## CIFAR-10 normalization vals (3 channels, RGB)\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std  = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        "    ##persistent_workers=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        "    ##persistent_workers=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQSPaCZJPhqe",
        "outputId": "fad9e19d-00c7-4977-f21e-f87d54e6e4a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR_CNN(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=131072, out_features=256, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "## CNN Model Definition\n",
        "class CIFAR_CNN(nn.Module):\n",
        "    def __init__(self): ## sets up the layers when the model is created\n",
        "        super().__init__() ## calls nn.Module to properly initialize Pytorch internals\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1), ## 3 input channels, 32 filters\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), ## 32 input channels, 64 filters\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 32 * 32 , 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CIFAR_CNN().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AeFuNZyrd5xR",
        "outputId": "b3f723ca-64e2-43c9-85c7-9a86175af183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300  Loss: 1.4667  Accuracy: 0.4785  Time: 22.13s\n",
            "Epoch 2/300  Loss: 0.9613  Accuracy: 0.6620  Time: 21.70s\n",
            "Epoch 3/300  Loss: 0.7038  Accuracy: 0.7547  Time: 22.45s\n",
            "Epoch 4/300  Loss: 0.4549  Accuracy: 0.8429  Time: 22.13s\n",
            "Epoch 5/300  Loss: 0.2028  Accuracy: 0.9332  Time: 22.05s\n",
            "Epoch 6/300  Loss: 0.0681  Accuracy: 0.9803  Time: 21.75s\n",
            "Epoch 7/300  Loss: 0.0261  Accuracy: 0.9932  Time: 21.99s\n",
            "Epoch 8/300  Loss: 0.0174  Accuracy: 0.9955  Time: 21.82s\n",
            "Epoch 9/300  Loss: 0.0250  Accuracy: 0.9923  Time: 21.79s\n",
            "Epoch 10/300  Loss: 0.0307  Accuracy: 0.9901  Time: 21.70s\n",
            "Epoch 11/300  Loss: 0.0257  Accuracy: 0.9916  Time: 21.32s\n",
            "Epoch 12/300  Loss: 0.0283  Accuracy: 0.9907  Time: 21.77s\n",
            "Epoch 13/300  Loss: 0.0268  Accuracy: 0.9911  Time: 21.70s\n",
            "Epoch 14/300  Loss: 0.0174  Accuracy: 0.9940  Time: 21.67s\n",
            "Epoch 15/300  Loss: 0.0131  Accuracy: 0.9961  Time: 21.82s\n",
            "Epoch 16/300  Loss: 0.0189  Accuracy: 0.9937  Time: 21.36s\n",
            "Epoch 17/300  Loss: 0.0290  Accuracy: 0.9906  Time: 21.89s\n",
            "Epoch 18/300  Loss: 0.0132  Accuracy: 0.9955  Time: 21.97s\n",
            "Epoch 19/300  Loss: 0.0128  Accuracy: 0.9956  Time: 21.71s\n",
            "Epoch 20/300  Loss: 0.0225  Accuracy: 0.9925  Time: 21.88s\n",
            "Epoch 21/300  Loss: 0.0229  Accuracy: 0.9926  Time: 21.50s\n",
            "Epoch 22/300  Loss: 0.0161  Accuracy: 0.9946  Time: 21.58s\n",
            "Epoch 23/300  Loss: 0.0234  Accuracy: 0.9922  Time: 21.84s\n",
            "Epoch 24/300  Loss: 0.0137  Accuracy: 0.9952  Time: 21.75s\n",
            "Epoch 25/300  Loss: 0.0150  Accuracy: 0.9951  Time: 21.77s\n",
            "Epoch 26/300  Loss: 0.0083  Accuracy: 0.9975  Time: 21.77s\n",
            "Epoch 27/300  Loss: 0.0110  Accuracy: 0.9965  Time: 21.64s\n",
            "Epoch 28/300  Loss: 0.0150  Accuracy: 0.9948  Time: 21.95s\n",
            "Epoch 29/300  Loss: 0.0154  Accuracy: 0.9952  Time: 21.95s\n",
            "Epoch 30/300  Loss: 0.0153  Accuracy: 0.9947  Time: 22.24s\n",
            "Epoch 31/300  Loss: 0.0105  Accuracy: 0.9967  Time: 21.95s\n",
            "Epoch 32/300  Loss: 0.0139  Accuracy: 0.9954  Time: 22.82s\n",
            "Epoch 33/300  Loss: 0.0140  Accuracy: 0.9958  Time: 22.08s\n",
            "Epoch 34/300  Loss: 0.0124  Accuracy: 0.9960  Time: 22.34s\n",
            "Epoch 35/300  Loss: 0.0136  Accuracy: 0.9954  Time: 22.31s\n",
            "Epoch 36/300  Loss: 0.0151  Accuracy: 0.9951  Time: 22.09s\n",
            "Epoch 37/300  Loss: 0.0182  Accuracy: 0.9939  Time: 22.33s\n",
            "Epoch 38/300  Loss: 0.0093  Accuracy: 0.9970  Time: 22.31s\n",
            "Epoch 39/300  Loss: 0.0074  Accuracy: 0.9978  Time: 21.74s\n",
            "Epoch 40/300  Loss: 0.0052  Accuracy: 0.9983  Time: 22.06s\n",
            "Epoch 41/300  Loss: 0.0091  Accuracy: 0.9974  Time: 22.08s\n",
            "Epoch 42/300  Loss: 0.0126  Accuracy: 0.9962  Time: 22.30s\n",
            "Epoch 43/300  Loss: 0.0161  Accuracy: 0.9952  Time: 22.31s\n",
            "Epoch 44/300  Loss: 0.0132  Accuracy: 0.9960  Time: 22.22s\n",
            "Epoch 45/300  Loss: 0.0128  Accuracy: 0.9960  Time: 21.86s\n",
            "Epoch 46/300  Loss: 0.0119  Accuracy: 0.9964  Time: 22.63s\n",
            "Epoch 47/300  Loss: 0.0065  Accuracy: 0.9980  Time: 22.23s\n",
            "Epoch 48/300  Loss: 0.0038  Accuracy: 0.9990  Time: 22.35s\n",
            "Epoch 49/300  Loss: 0.0112  Accuracy: 0.9968  Time: 22.35s\n",
            "Epoch 50/300  Loss: 0.0150  Accuracy: 0.9956  Time: 22.32s\n",
            "Epoch 51/300  Loss: 0.0096  Accuracy: 0.9971  Time: 22.25s\n",
            "Epoch 52/300  Loss: 0.0100  Accuracy: 0.9967  Time: 22.17s\n",
            "Epoch 53/300  Loss: 0.0095  Accuracy: 0.9971  Time: 22.59s\n",
            "Epoch 54/300  Loss: 0.0088  Accuracy: 0.9974  Time: 22.59s\n",
            "Epoch 55/300  Loss: 0.0084  Accuracy: 0.9973  Time: 22.59s\n",
            "Epoch 56/300  Loss: 0.0041  Accuracy: 0.9986  Time: 22.52s\n",
            "Epoch 57/300  Loss: 0.0090  Accuracy: 0.9975  Time: 22.58s\n",
            "Epoch 58/300  Loss: 0.0165  Accuracy: 0.9958  Time: 22.45s\n",
            "Epoch 59/300  Loss: 0.0144  Accuracy: 0.9958  Time: 22.15s\n",
            "Epoch 60/300  Loss: 0.0133  Accuracy: 0.9962  Time: 22.92s\n",
            "Epoch 61/300  Loss: 0.0073  Accuracy: 0.9977  Time: 22.39s\n",
            "Epoch 62/300  Loss: 0.0036  Accuracy: 0.9989  Time: 22.37s\n",
            "Epoch 63/300  Loss: 0.0026  Accuracy: 0.9993  Time: 22.33s\n",
            "Epoch 64/300  Loss: 0.0030  Accuracy: 0.9989  Time: 22.46s\n",
            "Epoch 65/300  Loss: 0.0096  Accuracy: 0.9974  Time: 22.10s\n",
            "Epoch 66/300  Loss: 0.0164  Accuracy: 0.9952  Time: 22.39s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4201801445.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 300\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "epoch_times = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Tracking\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    accuracy = correct / total\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    train_losses.append(avg_loss)\n",
        "    train_accuracies.append(accuracy)\n",
        "    epoch_times.append(elapsed)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}  \"\n",
        "          f\"Loss: {avg_loss:.4f}  \"\n",
        "          f\"Accuracy: {accuracy:.4f}  \"\n",
        "          f\"Time: {elapsed:.2f}s\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from torchvision.datasets import CIFAR10\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "id": "Lsx2eK1UyDGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## CIFAR-10 normalization vals (3 channels, RGB)\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std  = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        "    ##persistent_workers=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        "    ##persistent_workers=True\n",
        ")"
      ],
      "metadata": {
        "id": "i2LAb1n1yGnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## CNN Model Definition\n",
        "class CIFAR_CNN(nn.Module):\n",
        "    def __init__(self): ## sets up the layers when the model is created\n",
        "        super().__init__() ## calls nn.Module to properly initialize Pytorch internals\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1), ## 3 input channels, 32 filters\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2), ## from 32 x 32 to 16 x 16\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), ## 32 input channels, 64 filters\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2), ##\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 2 * 2, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CIFAR_CNN().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "pvwKkTuRyK9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 300\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "epoch_times = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Tracking\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    accuracy = correct / total\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    train_losses.append(avg_loss)\n",
        "    train_accuracies.append(accuracy)\n",
        "    epoch_times.append(elapsed)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}  \"\n",
        "          f\"Loss: {avg_loss:.4f}  \"\n",
        "          f\"Accuracy: {accuracy:.4f}  \"\n",
        "          f\"Time: {elapsed:.2f}s\")"
      ],
      "metadata": {
        "id": "o6KkU4UmyOQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from torchvision.datasets import CIFAR10\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "id": "5fbZnZ-6yQIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## CIFAR-10 normalization vals (3 channels, RGB)\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std  = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        "    ##persistent_workers=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        "    ##persistent_workers=True\n",
        ")"
      ],
      "metadata": {
        "id": "qMjkxMRRyU7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self,channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "        ## Conv -> ReLU -> Conv -> Skip connection -> ReLU\n",
        "\n",
        "    def forward(self, x):\n",
        "         residual = x\n",
        "         out = self.conv1(x)\n",
        "         out = self.bn1(out)\n",
        "         out = self.relu(out)\n",
        "         out = self.conv2(out)\n",
        "         out = out + residual ## skip connection\n",
        "         out = self.relu(out) ## final ReLU\n",
        "         return out\n",
        "\n",
        "class ResNet10(nn.Module):\n",
        "   def __init__(self): ## sets up the layers when the model is created\n",
        "        super().__init__() ## calls nn.Module to properly initialize Pytorch internals\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        blocks = []\n",
        "        for _ in range(10):\n",
        "            blocks.append(ResidualBlock(64))\n",
        "        self.res_blocks = nn.Sequential(*blocks)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1)) ##from 64 x 32 x 32 to 64 x 1 x 1\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "   def forward(self, x):\n",
        "        x = self.stem(x) ## 64 x 32 x 32\n",
        "        x = self.res_blocks(x) ## apply intial conv/ReLU\n",
        "        x = self.pool(x) ## 64 x 1 x 1\n",
        "        x = torch.flatten(x,1) ## just 64\n",
        "\n",
        "        return self.classifier(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNet10().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "Tvns6x64yXyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 300\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "epoch_times = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Tracking\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    accuracy = correct / total\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    train_losses.append(avg_loss)\n",
        "    train_accuracies.append(accuracy)\n",
        "    epoch_times.append(elapsed)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}  \"\n",
        "          f\"Loss: {avg_loss:.4f}  \"\n",
        "          f\"Accuracy: {accuracy:.4f}  \"\n",
        "          f\"Time: {elapsed:.2f}s\")"
      ],
      "metadata": {
        "id": "k9TSH-0MyahI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from torchvision.datasets import CIFAR10\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
      ],
      "metadata": {
        "id": "wsiYoblOye5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self,channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        ## Conv -> ReLU -> Conv -> Skip connection -> ReLU\n",
        "\n",
        "    def forward(self, x):\n",
        "         residual = x\n",
        "         out = self.conv1(x)\n",
        "         out = self.relu(out)\n",
        "         out = self.conv2(out)\n",
        "         out = out + residual ## skip connection\n",
        "         out = self.relu(out) ## final ReLU\n",
        "         return out\n",
        "\n",
        "class ResNet10(nn.Module):\n",
        "   def __init__(self): ## sets up the layers when the model is created\n",
        "        super().__init__() ## calls nn.Module to properly initialize Pytorch internals\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        blocks = []\n",
        "        for _ in range(10):\n",
        "            blocks.append(ResidualBlock(64))\n",
        "        self.res_blocks = nn.Sequential(*blocks)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1)) ##from 64 x 32 x 32 to 64 x 1 x 1\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.3), ## dropout\n",
        "            nn.Linear(64,10)\n",
        "        )\n",
        "\n",
        "\n",
        "   def forward(self, x):\n",
        "        x = self.stem(x) ## 64 x 32 x 32\n",
        "        x = self.res_blocks(x) ## apply intial conv/ReLU\n",
        "        x = self.pool(x) ## 64 x 1 x 1\n",
        "        x = torch.flatten(x,1) ## just 64\n",
        "\n",
        "        return self.classifier(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNet10().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "hdP9ydbsyoFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 300\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "epoch_times = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Tracking\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    accuracy = correct / total\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    train_losses.append(avg_loss)\n",
        "    train_accuracies.append(accuracy)\n",
        "    epoch_times.append(elapsed)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}  \"\n",
        "          f\"Loss: {avg_loss:.4f}  \"\n",
        "          f\"Accuracy: {accuracy:.4f}  \"\n",
        "          f\"Time: {elapsed:.2f}s\")"
      ],
      "metadata": {
        "id": "nzu576vvyqkv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}